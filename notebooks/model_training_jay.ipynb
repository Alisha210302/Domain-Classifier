{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jayes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jayes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\jayes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"../Dataset/processed_data/final_dataset.csv\")  # Ensure the dataset exists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Combine domain and subdomain into a single label (multi-label classification)\n",
    "df[\"labels\"] = df[\"domain\"] + \" | \" + df[\"sub_domain\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "# Text Preprocessing Function\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove special characters, numbers, and punctuation\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    text = text.translate(str.maketrans(\n",
    "        '', '', string.punctuation))  # Remove punctuation\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords and lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(word)\n",
    "              for word in tokens if word not in stop_words]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply text preprocessing\n",
    "df[\"cleaned_description\"] = df[\"description\"].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert text into numerical features using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # Limit vocabulary size\n",
    "X = vectorizer.fit_transform(df[\"cleaned_description\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Encode labels (convert categorical labels into numbers)\n",
    "y = df[\"labels\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert labels into numerical format\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train Logistic Regression Model\n",
    "model = LogisticRegression(max_iter=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.7738\n",
      "Classification Report:\n",
      "                                     precision    recall  f1-score   support\n",
      "\n",
      "                 Ecommerce | Books       0.88      0.88      0.88      2380\n",
      "Ecommerce | Clothing & Accessories       0.97      0.97      0.97      1748\n",
      "           Ecommerce | Electronics       0.95      0.93      0.94      2185\n",
      "             Ecommerce | Household       0.94      0.97      0.95      3884\n",
      "    Medical | Allergy & Immunology       0.00      0.00      0.00         3\n",
      "          Medical | Anesthesiology       1.00      0.30      0.46        10\n",
      "              Medical | Cardiology       0.80      0.36      0.50        11\n",
      "             Medical | Dermatology       0.00      0.00      0.00        10\n",
      "                     Medical | ENT       0.00      0.00      0.00         1\n",
      "      Medical | Emergency Medicine       0.50      0.25      0.33         8\n",
      "           Medical | Endocrinology       0.00      0.00      0.00         8\n",
      "         Medical | General Surgery       1.00      0.40      0.57         5\n",
      "              Medical | Geriatrics       0.00      0.00      0.00         4\n",
      "              Medical | Gynecology       0.00      0.00      0.00         2\n",
      "              Medical | Hematology       1.00      0.23      0.38        13\n",
      "     Medical | Infectious Diseases       0.50      0.36      0.42        14\n",
      "       Medical | Internal Medicine       0.00      0.00      0.00         6\n",
      "              Medical | Nephrology       0.50      0.42      0.45        12\n",
      "               Medical | Neurology       0.17      0.11      0.13         9\n",
      "              Medical | Obstetrics       0.00      0.00      0.00         2\n",
      "                Medical | Oncology       0.50      0.55      0.52        11\n",
      "           Medical | Ophthalmology       0.00      0.00      0.00         4\n",
      "             Medical | Orthopedics       0.58      0.73      0.65        15\n",
      "          Medical | Otolaryngology       0.00      0.00      0.00         2\n",
      "               Medical | Pathology       1.00      0.12      0.22        16\n",
      "              Medical | Pediatrics       0.00      0.00      0.00        11\n",
      "         Medical | Plastic Surgery       1.00      0.20      0.33        10\n",
      "             Medical | Pulmonology       0.00      0.00      0.00         1\n",
      "               Medical | Radiology       0.00      0.00      0.00         6\n",
      "   Medical | Reproductive Medicine       1.00      0.25      0.40         4\n",
      "                   News | business       0.64      0.66      0.65      1151\n",
      "              News | entertainment       0.56      0.53      0.55      1135\n",
      "               News | food & drink       0.65      0.68      0.67       972\n",
      "                  News | parenting       0.63      0.60      0.61      1011\n",
      "                   News | politics       0.62      0.60      0.61      1127\n",
      "                      News | sport       0.99      0.92      0.96       187\n",
      "                     News | sports       0.56      0.67      0.61       995\n",
      "             News | style & beauty       0.69      0.64      0.66      1011\n",
      "                       News | tech       0.99      0.83      0.90       143\n",
      "                     News | travel       0.63      0.60      0.61       955\n",
      "                   News | wellness       0.57      0.60      0.59       982\n",
      "                 News | world news       0.61      0.59      0.60       975\n",
      "\n",
      "                          accuracy                           0.77     21039\n",
      "                         macro avg       0.51      0.38      0.41     21039\n",
      "                      weighted avg       0.77      0.77      0.77     21039\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Jay\\CDAC\\Project\\Domain Classifier\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Jay\\CDAC\\Project\\Domain Classifier\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Jay\\CDAC\\Project\\Domain Classifier\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the Model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Testing the model with a new description\n",
    "def predict_domain(text):\n",
    "    cleaned_text = preprocess_text(text)\n",
    "    vectorized_text = vectorizer.transform([cleaned_text])\n",
    "    predicted_label = model.predict(vectorized_text)\n",
    "    return label_encoder.inverse_transform(predicted_label)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Domain: Ecommerce | Household\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example\n",
    "sample_text = \"\"\"Modern Chesterfield Design: Designed with the traditional modern Chesterfield style in mind decorative elements, scrolled arms, and fashionable legs, this piece has all the important features of the classic modern Chesterfield style.\n",
    "Button Tufted Diamonds Stitch: The chaise's button-tufted stitching adds an additional level of refinement to its elegant form. The diamond stitch design provides and wooden leg some roughness without compromising comfort. PRODUCT DIMENSION: 220 Lx 90 Dx 78H-(W x D x H).\n",
    "The seat, back and armrests are thickly padded, which makes the chaise lounge very comfortable, and the sturdy wooden feet contribute to the stability of the construction.\n",
    "DURABLE DESIGN - A naturally strong frame is wrapped in supportive foam padding and durable polyester fabric, it has a maximum weight capacity of 498.2 lbs; the cushions are secured to the frame and are not removable.\n",
    "MULTIPURPOSE DESIGN: An attractive, multipurpose design makes it perfect for various spaces such as your living room, college dorm, home office, and more.\n",
    "Our delivery service is very fast, we deliver the order to the customer with 3 days guarantee after dispatch.\n",
    "[Customer Guarantee] We want all of our customers to feel 100% satisfied. If you have any questions, please email us in time, we guarantee to reply within 24 hours and give you a satisfactory reply.\"\"\"\n",
    "print(\"Predicted Domain:\", predict_domain(sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model, Vectorizer, and Label Encoder saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(model, \"../models/logistic_regression/logistic_regression_model.pkl\")\n",
    "\n",
    "# Save the TF-IDF vectorizer\n",
    "joblib.dump(vectorizer, \"../models/logistic_regression/tfidf_vectorizer.pkl\")\n",
    "\n",
    "# Save the Label Encoder\n",
    "joblib.dump(label_encoder, \"../models/logistic_regression/label_encoder.pkl\")\n",
    "\n",
    "print(\"Model, Vectorizer, and Label Encoder saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "loaded_model = joblib.load(\n",
    "    \"../models/logistic_regression/logistic_regression_model.pkl\")\n",
    "\n",
    "# Load the TF-IDF vectorizer\n",
    "loaded_vectorizer = joblib.load(\n",
    "    \"../models/logistic_regression/tfidf_vectorizer.pkl\")\n",
    "\n",
    "# Load the Label Encoder\n",
    "loaded_label_encoder = joblib.load(\n",
    "    \"../models/logistic_regression/label_encoder.pkl\")\n",
    "\n",
    "# Function to predict domain from new text\n",
    "\n",
    "\n",
    "def predict_domain(text):\n",
    "    cleaned_text = preprocess_text(text)  # Apply same preprocessing\n",
    "    vectorized_text = loaded_vectorizer.transform(\n",
    "        [cleaned_text])  # Convert text to features\n",
    "    predicted_label = loaded_model.predict(vectorized_text)  # Predict label\n",
    "    # Convert back to text\n",
    "    return loaded_label_encoder.inverse_transform(predicted_label)[0]\n",
    "\n",
    "\n",
    "# Test the saved model\n",
    "sample_text = \"This article discusses convolutional neural networks and AI.\"\n",
    "print(\"Predicted Domain:\", predict_domain(sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
